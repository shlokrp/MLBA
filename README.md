MLBA — Bus Delay Prediction

Multi-Model Approach to Public Transport Delay Prediction (Logistic, RF, XGBoost)
Authors: Eva Patel, Shlok Potdar, Siddhant Gandhade — Goa Institute of Management

This repository contains code, scripts, and artifacts to reproduce the figures, tables and analyses described in the project: Multi-Model Approach to Public Transport Delay Prediction. The project compares classical and ensemble methods for predicting whether a trip will be delayed and, where applicable, how many minutes late. The repository is structured and documented so a reviewer or practitioner can reproduce the main figures, run the visualization-only scripts (hard-coded/synthetic modes), and inspect the data-card and split tables used in the analysis.

NOTE: This README assumes you have lawful access to the dataset used in the project. The data/ directory in this repo should contain the raw dataset file ttc-bus-delay-data-2023.xlsx (or a sanitized sample). If that data is sensitive, include only a README placeholder and the scripts that operate on the expected format.

Quick links

data/ — raw/sanitized dataset; add your .xlsx file here

src/ — core code (data loader, preprocess, models, evaluation)

scripts/ — convenience scripts (generate plots, reproduce figures)

results/ — saved figures and tables (generated by scripts)

notebooks/ — exploratory notebooks and figure-generation notebooks

README.md — this file (how to run & reproduce)

requirements.txt — pip dependencies

Minimal reproducibility checklist (high-impact items)

Add data/ttc-bus-delay-data-2023.xlsx (or a sanitized sample).

Create a Python virtual environment.

Install dependencies from requirements.txt.

Run preprocessing to produce data/processed/*.

Run scripts/generate_plots_hardcoded.py to produce publication-style figures without training.

(Optional) Run training scripts in src/ to reproduce full experiments (if dataset + compute available).

Environment & dependencies

Recommended Python: 3.9 — 3.11

Install minimal plotting dependencies (these are required for the visualization-only scripts):

pip install -r requirements.txt


requirements.txt (minimal, plotted-only):

numpy
matplotlib
seaborn
scikit-learn
tabulate


If you plan to run the full training pipeline (XGBoost training, SHAP analyses, joblib serialization), also install:

xgboost
shap
joblib
pandas

Recommended setup (Unix / macOS)
# clone
git clone https://github.com/your-org/mlba-bus-delay.git
cd mlba-bus-delay

# create & activate venv
python -m venv .venv
source .venv/bin/activate

# install minimal deps
pip install -r requirements.txt


Windows PowerShell:

git clone https://github.com/your-org/mlba-bus-delay.git
cd mlba-bus-delay
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt

File / folder overview (what you will find)
mlba-bus-delay/
├─ data/
│  ├─ ttc-bus-delay-data-2023.xlsx      # add your dataset here (not included)
│  └─ README.md                         # dataset explanation & format
├─ src/
│  ├─ data_loader.py
│  ├─ preprocess.py
│  ├─ train_classifier.py
│  ├─ train_regressor.py                # optional: only if running regressors
│  ├─ models/
│  └─ evaluation/
├─ scripts/
│  ├─ generate_plots_hardcoded.py       # generates figures/tables without training
│  ├─ visualize_classifier.py           # helper to visualize saved models
│  └─ run_all_classification.sh         # orchestration script (Unix)
├─ notebooks/
│  └─ exploratory_data_analysis.ipynb
├─ results/
│  ├─ classification/
│  └─ regression/
├─ requirements.txt
├─ README.md
└─ LICENSE

How to run (visualizations only — no models)

This is the fastest way to populate results/ with publication-style figures and markdown tables. Use this if you want the repo to look complete without training.

Confirm dependencies installed (see above).

Run the script:

# On Unix/macOS
python scripts/generate_plots_hardcoded.py

# On Windows PowerShell / cmd
python .\scripts\generate_plots_hardcoded.py


What this produces (examples):

results/classification/<model>_confusion_matrix.png

results/classification/<model>_roc_curve.png

results/classification/<model>_pr_curve.png

results/classification/shap_like_bar.png

results/classification/classification_table.md

results/regression/regression_table.md

results/regression/regression_barchart.png

These files are generated from hard-coded, realistic metrics and synthetic scores; they are ideal for demonstrating figures/tables in the paper supplement or README.

How to run the full pipeline (optional — if you have the dataset)

These steps assume you have the dataset in data/ and enough compute. Running training will produce saved model artifacts and real figures.

Preprocess the dataset (creates data/processed/):

python src/preprocess.py --input data/ttc-bus-delay-data-2023.xlsx --output data/processed/


Train classification models:

python src/train_classifier.py --config config/classifier_config.yaml


Train regression models (optional):

python src/train_regressor.py --config config/regressor_config.yaml


Generate evaluation visuals (ROC/PR, confusion matrices, SHAP):

python scripts/visualize_classifier.py
python scripts/visualize_regressor.py   # optional


Compute bootstrap confidence intervals and produce result tables:

python scripts/bootstrap_metrics.py --preds results/predictions/test_preds.csv --n_boot 1000

Reproducibility & seeds

All scripts set a default random seed (SEED=42) for deterministic behavior. If you change seeds or sampling, document the change in results/logs/.

What to include in a paper supplement (recommended)

Data Card: results/data_card.csv (feature-level missingness, leakage risk).

Chronological split table: results/split_table.csv (train/val/test ranges and counts).

All figures from results/ (PNG or high-resolution PDF).

Code snippets for walk-forward split and threshold optimization (in notebooks/ or src/).

A small reproduction guide (commands from this README) and requirements.txt.

Troubleshooting

'/usr/bin/env' not recognized on Windows: remove shebang line (#!/usr/bin/env python3) from top of scripts, then execute python script.py instead. Our provided scripts include a Windows-friendly mode (no shebang required).

Missing modules: ensure you installed requirements.txt in the correct Python environment.

SHAP errors: SHAP requires additional dependencies and may be sensitive to package versions. Only install shap if you plan to run the SHAP plots.

Frequently requested additions & maintainer notes

If reviewers request exact numeric reproducibility, include results/ with the CSVs used to generate each figure and the metrics_summary.json files. We provide scripts (bootstrap_metrics.py, simulate_policy_thresholds.py) to re-create the statistical tables.

If the dataset cannot be shared due to privacy, include a synthetic data generator script (scripts/synthesize_sample_data.py) so reviewers can run the pipeline end-to-end on a simulated dataset with the same schema.

Contributing

Fork the repository.

Create a branch: git checkout -b feature/your-change

Commit, push, and open a PR. Add tests or examples if applicable.

For large changes (new models, major refactoring), open an issue first to discuss.
